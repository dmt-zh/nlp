{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49430a9-5cc0-4cd6-8c47-e79a4dec94bf",
   "metadata": {},
   "source": [
    "# Представление текста. Часть 2.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Задачи:\n",
    "- **Embeddings**\n",
    "- **Word2Vec**\n",
    "- **SentenceTransformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37153a62-e75c-45e0-a81b-337d5ace8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек для дальнейшей работы\n",
    "from gensim.models import KeyedVectors\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606a7c8-5d4b-4730-8b79-442a15f0b795",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebf2bd-ab93-40f2-9306-e06141370420",
   "metadata": {},
   "source": [
    "#### Функция для загрузки моделей Word2Vec\n",
    "\n",
    "Для трансформации слов в эмбеддинг с помощью библиотеки `gensim` нужно загрузить натренированную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b41ce10-7afc-478c-9334-e573ca3ad998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v_model(model_path: Path, model_url: str) -> None:\n",
    "    \"\"\"Функция скачивает модель по указанному пути.\"\"\"\n",
    "\n",
    "    print(f'Started to load Word2Vec model.', flush=True)\n",
    "    download_path = model_path.parent\n",
    "    download_path.mkdir(exist_ok=True, parents=True)\n",
    "    archive_path = download_path.joinpath('model.zip')\n",
    "    urlretrieve(model_url, archive_path)\n",
    "\n",
    "    with ZipFile(archive_path) as zip_obj:\n",
    "        file_names = zip_obj.namelist()\n",
    "        for file in file_names:\n",
    "            if file.endswith('.bin'):\n",
    "                zip_obj.extract(file, path=download_path)\n",
    "        archive_path.unlink()\n",
    "    print('Model is downloaded!', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a44bc9-d30e-459f-8f4b-cae362861ccd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8c28a-bce6-4a09-be31-c81ec0342ece",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Эмбеддинг (англ. _embedding_) — это вектор в виде массива чисел, который получается после преобразования текста языковой моделью.\n",
    "<img src='https://github.com/dmt-zh/nlp/blob/main/images/word_embedding.jpg' width=\"640\" height=\"328\" >\n",
    "\n",
    "В общем виде, эмбеддинги делятся на:\n",
    "- Word Embeddings — слова преобразуют в векторы, так что слова с похожим значением имеют похожие векторные представления.\n",
    "- Sentence Embeddings — создание векторных представлений для целых предложений или даже абзацев, улавливая гораздо более тонкие нюансы языка.\n",
    "\n",
    "В NLP, эмбеддинги слов используются для того, чтобы компьютер мог понять, что слова «кошка» и «котенок» связаны между собой ближе, чем, скажем, «кошка» и «окошко». Это достигается путем присвоения словам векторов, которые отражают их значение и контекстное использование в языке.\n",
    "\n",
    "Векторное представление текста (эмбеддинги) используется для:\n",
    "- улучшения качества поиска — эмбеддинги позволяют оценивать сходство между текстовыми запросами на основе расстояния между соответствующими векторами;\n",
    "- уменьшения размерности данных — с помощью эмбеддингов вы можете представить текстовые запросы в виде числовых векторов, что позволяет снизить размерность данных и ускорить их обработку;\n",
    "- обеспечения универсальности — эмбеддинги можно использовать для различных задач обработки естественного языка, таких как Retrieval Augmented Generation (RAG), классификация текстов, кластеризация и других."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27efdf-ff48-4c62-8e97-21658221432f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85fa35e-c936-474a-8480-a617218ab176",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "\n",
    "Word2Vec использует нейронные сети для обучения векторных представлений слов из больших наборов текстовых данных. Существуют две основные архитектуры Word2Vec:\n",
    "- **Continuous bag of words (CBOW)**: предсказывает текущее слово на основе контекста (окружающих слов). Например, в предложении \"Собака лает на ___\", CBOW попытается угадать недостающее слово (например, \"почтальона\") на основе окружающих слов.\n",
    "<img src='https://github.com/dmt-zh/nlp/blob/main/images/cbow.jpg' width=\"628\" height=\"428\" >\n",
    "\n",
    "- **Skip-gram**: работает наоборот по сравнению с CBOW. Использует текущее слово для предсказания окружающих его слов в предложении. Например, если взять слово \"кошка\", модель попытается предсказать слова, которые часто встречаются в окружении слова \"кошка\", такие как \"мышь\", \"мяукает\" и т.д.\n",
    "<img src='https://github.com/dmt-zh/nlp/blob/main/images/skip_gram.jpg' width=\"630\" height=\"428\" >\n",
    "\n",
    "<br>\n",
    "\n",
    "Перечень предобученных [**моделей Word2Vec**](https://github.com/piskvorky/gensim-data?tab=readme-ov-file#models)\n",
    "Перечень предобученных [**моделей Word2Vec для русского языка**](https://rusvectores.org/ru/models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed366f7-17b8-4b14-b992-2355511692b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачаем обученную модель Word2Vec для русского языка\n",
    "ru_w2v_model_path = Path('./env/w2v_ru_model/model.bin').resolve()\n",
    "model_url = 'https://vectors.nlpl.eu/repository/20/180.zip'\n",
    "if not ru_w2v_model_path.exists():\n",
    "    load_w2v_model(ru_w2v_model_path, model_url)\n",
    "\n",
    "ru_w2v_model = KeyedVectors.load_word2vec_format(ru_w2v_model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b331d-d44b-4996-bef3-635f4dad3136",
   "metadata": {},
   "source": [
    "С помощью модели Word2Vec сконвертируем слово «кошка» в эмбеддинг и посмотрим наиболее близкие по смыслу слова. Модели скачанные с сервиса RusVectōrēs принимают на вход слово с указанием части речи, например `word_NOUN`, где `_NOUN` существительное.\n",
    "\n",
    "Перечень сокращений для частей речи можно посмотреть на сайте [**Universal Dependencies**](https://universaldependencies.org/u/pos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a791dec-4455-46ec-989d-d686b467b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность эмбеддинга: (300,)\n",
      "Первые 5 значений эмбеддинга: [ 1.1034642  1.3057697 -2.3964143  0.9756819  0.1359841]\n"
     ]
    }
   ],
   "source": [
    "# Эмбеддинг для слова «кошка»\n",
    "w2v_emb = ru_w2v_model.get_vector('кошка_NOUN')\n",
    "print(f'Размерность эмбеддинга: {w2v_emb.shape}')\n",
    "print(f'Первые 5 значений эмбеддинга: {w2v_emb[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec658049-5c45-4f6b-91b8-2aae854e1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('кот_NOUN', 0.8207471966743469)\n",
      "('котенок_NOUN', 0.7216677069664001)\n",
      "('котенка_NOUN', 0.6935656070709229)\n",
      "('котенок_VERB', 0.6845224499702454)\n",
      "('собака_NOUN', 0.6829918622970581)\n"
     ]
    }
   ],
   "source": [
    "# Наиболее близкие по смыслу слова\n",
    "print(*ru_w2v_model.most_similar('кошка_NOUN', topn=5), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf0ac1-3db8-4cbf-b339-30fbf7656b5b",
   "metadata": {},
   "source": [
    "Из полученного результата видно, что наиболее близким по смыслу словом для слова «кошка» является «кот»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c46fc1-2117-42cf-ab53-d1b299b7a8da",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123871eb-f27a-48cb-ac14-ce7239c1f034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
